{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d29306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ae7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset (handwritten digits)\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ec0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values (0-1 range)\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe39cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build an ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten 28x28 image to 1D\n",
    "    keras.layers.Dense(128, activation='relu'),  # Hidden layer with 128 neurons\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer (10 classes for digits 0-9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e73547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927a2f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.4352 - val_accuracy: 0.9574 - val_loss: 0.1430\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1243 - val_accuracy: 0.9676 - val_loss: 0.1112\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0818 - val_accuracy: 0.9751 - val_loss: 0.0833\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0591 - val_accuracy: 0.9755 - val_loss: 0.0808\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0433 - val_accuracy: 0.9722 - val_loss: 0.0908\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0355 - val_accuracy: 0.9750 - val_loss: 0.0837\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0278 - val_accuracy: 0.9770 - val_loss: 0.0773\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0239 - val_accuracy: 0.9781 - val_loss: 0.0769\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0173 - val_accuracy: 0.9767 - val_loss: 0.0848\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0136 - val_accuracy: 0.9770 - val_loss: 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved as 'mnist_ann.h5'\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"mnist_ann.h5\")\n",
    "\n",
    "print(\"Model trained and saved as 'mnist_ann.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6ffaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tkinter import Tk, filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0b6b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ANN model\n",
    "try:\n",
    "    model = tf.keras.models.load_model(\"mnist_ann.h5\")\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading model: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82275ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select an image file\n",
    "def upload_image():\n",
    "    Tk().withdraw()  # Hide Tkinter root window\n",
    "    file_path = filedialog.askopenfilename(title=\"Select an image\", filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg\")])\n",
    "    return file_path if file_path else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8541996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "    if img is None:\n",
    "        print(\"Error: Could not read image file.\")\n",
    "        exit()\n",
    "\n",
    "    img = cv2.resize(img, (28, 28))  # Resize to 28x28\n",
    "    img = cv2.bitwise_not(img)  # Invert colors (MNIST is black on white)\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    img = img.reshape(1, 28, 28)  # Reshape for ANN model input\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f17ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: The uploaded digit is 5\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "file_path = upload_image()\n",
    "\n",
    "if file_path:\n",
    "    img_processed = preprocess_image(file_path)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_processed)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "    \n",
    "    # Show the uploaded image and prediction\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img_processed.reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted Digit: {predicted_digit}\", fontsize=14, color=\"blue\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Prediction: The uploaded digit is {predicted_digit}\")\n",
    "\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e41ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
